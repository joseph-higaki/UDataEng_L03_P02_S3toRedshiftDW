{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Draft\n",
    "This notebook is to scrap / test code towards the actual ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import json\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('aws.cfg'))\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "HOST              = config.get('CLUSTER','HOST')\n",
    "DB_NAME           = config.get('CLUSTER','DB_NAME')\n",
    "DB_USER           = config.get('CLUSTER','DB_USER')\n",
    "DB_PASSWORD       = config.get('CLUSTER','DB_PASSWORD')\n",
    "DB_PORT           = config.get('CLUSTER','DB_PORT')\n",
    "\n",
    "IAM_ROLE        = config.get('IAM_ROLE','ARN')\n",
    "\n",
    "LOG_DATA        = config.get('S3','LOG_DATA')\n",
    "LOG_JSONPATH     = config.get('S3','LOG_JSONPATH')\n",
    "SONG_DATA        = config.get('S3','SONG_DATA')\n",
    "BUCKET_REGION    = config.get('S3','BUCKET_REGION')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHeck S3 contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                       region_name= BUCKET_REGION,\n",
    "                       aws_access_key_id= KEY,\n",
    "                       aws_secret_access_key= SECRET\n",
    "                   )\n",
    "\n",
    "bucket = s3.Bucket('udacity-dend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing purposes I'm only using A/A/A\n",
    "If I upload the entire song dataset, it takes 100 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for obj in bucket.objects.filter(Prefix=\"song-data/A/A\"):\n",
    "#for obj in bucket.objects.filter(Prefix=\"log-data/2018/11/2018-11-01-events.json\"):\n",
    "    key = obj.key    \n",
    "    count += 1\n",
    "    # print(key)\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for obj in bucket.objects.all():\n",
    "#for obj in bucket.objects.filter(Prefix=\"log_json_path.json\"):\n",
    "for obj in bucket.objects.filter(Prefix=\"song-data/A/A/A/TRAAAAK128F9318786.json\"):\n",
    "#for obj in bucket.objects.filter(Prefix=\"log-data/2018/11/2018-11-01-events.json\"):\n",
    "    key = obj.key    \n",
    "    body = obj.get()['Body'].read() \n",
    "    print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check number of files / entities\n",
    "- Number of song files should match staging_songs.count\n",
    "- NUmber of log entities?? should match staging_events.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Song Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385253\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for i in bucket.objects.filter(Prefix=\"song-data/\"):\n",
    "  count += 1\n",
    "\n",
    "#list(map(lambda i: count = count + 1, bucket.objects.filter(Prefix=\"song-data/\")))\n",
    "\n",
    "#c = collections Counter()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "#for obj in bucket.objects.filter(Prefix=\"log-data/2018/11/2018-11-01-events.json\"):\n",
    "for obj in bucket.objects.filter(Prefix=\"log-data/\"):\n",
    "  text = obj.get()['Body'].read().decode('utf-8')  \n",
    "  df = pd.read_json(text, lines=True)\n",
    "  count += len(df.index)  \n",
    "  \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Redshift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DB_USER, DB_PASSWORD, HOST, DB_PORT, DB_NAME)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Staging Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS staging_events;\n",
    "CREATE TABLE staging_events \n",
    "(\n",
    "  artist varchar(1000),\n",
    "  auth varchar,\n",
    "  firstName varchar,\n",
    "  gender varchar,\n",
    "  itemInSession varchar,\n",
    "  lastName varchar,\n",
    "  length varchar,\n",
    "  level varchar,\n",
    "  location varchar,\n",
    "  method varchar,\n",
    "  page varchar,\n",
    "  registration varchar,\n",
    "  sessionId varchar,\n",
    "  song varchar(1000),\n",
    "  status varchar,\n",
    "  ts varchar,\n",
    "  userAgent varchar,\n",
    "  userId varchar\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS staging_songs;\n",
    "CREATE TABLE staging_songs \n",
    "(\n",
    "  song_id varchar,\n",
    "  num_songs varchar,\n",
    "  title varchar(1000), \n",
    "  name varchar(1000),\n",
    "  latitude varchar,\n",
    "  year varchar,\n",
    "  duration varchar,\n",
    "  artist_id varchar,\n",
    "  artist_longitude varchar,\n",
    "  artist_location  varchar(1000)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataWarehouse tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "drop table if exists users;\n",
    "create table if not exists users\n",
    "(\n",
    "    user_id int not null primary key sortkey,\n",
    "    first_name varchar not null,\n",
    "    last_name varchar not null,\n",
    "    gender varchar not null,\n",
    "    level varchar not null\n",
    ") diststyle ALL;\n",
    "\n",
    "drop table if exists time;\n",
    "create table if not exists time\n",
    "(\n",
    "  start_time timestamp without time zone not null primary key sortkey,\n",
    "  hour int not null,\n",
    "  day int not null,\n",
    "  week int not null,\n",
    "  month int not null,\n",
    "  year int not null,\n",
    "  day_of_week int not null,\n",
    "  day_of_week_name varchar not null,\n",
    "  is_weekend bool not null\n",
    ") diststyle ALL;\n",
    "\n",
    "drop table if exists songplays;\n",
    "create table if not exists songplays\n",
    "(\n",
    "    songplay_id int IDENTITY(0,1) primary key,\n",
    "    start_time timestamp without time zone not null sortkey,\n",
    "    user_id int not null,\n",
    "    level varchar not null,\n",
    "    song_id varchar distkey,\n",
    "    song_title varchar(1000) not null,\n",
    "    artist_id varchar,\n",
    "    artist_name varchar(1000) not null,\n",
    "    session_id int  not null,\n",
    "    location varchar(1000) not null,\n",
    "    user_agent varchar  not null,\n",
    "    stream_duration decimal \n",
    ") diststyle KEY;\n",
    "\n",
    "drop table if exists songs;\n",
    "create table if not exists songs\n",
    "(\n",
    "    song_id varchar not null primary key distkey,\n",
    "    title varchar(1000) not null sortkey,\n",
    "    artist_id varchar not null,\n",
    "    year int not null,\n",
    "    duration decimal not null\n",
    ") diststyle KEY;\n",
    "\n",
    "drop table if exists artist_names;\n",
    "create table if not exists artist_names\n",
    "(\n",
    "    name varchar(1000) not null primary key sortkey,\n",
    "    artist_id varchar not null,        \n",
    "    latitude decimal null,\n",
    "    longitude decimal null,\n",
    "    location varchar(1000) null\n",
    ") diststyle ALL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Events / Log from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cxxnfuxeuzhw.us-east-1.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>8056</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(8056,)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(1) from staging_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "copy staging_events \n",
    "from 's3://udacity-dend/log-data' \n",
    "iam_role 'arn:aws:iam::147551276302:role/dwhRole'\n",
    "region 'us-west-2'\n",
    "json 's3://udacity-dend/log_json_path.json';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>artist</th>\n",
       "            <th>auth</th>\n",
       "            <th>firstname</th>\n",
       "            <th>gender</th>\n",
       "            <th>iteminsession</th>\n",
       "            <th>lastname</th>\n",
       "            <th>length</th>\n",
       "            <th>level</th>\n",
       "            <th>location</th>\n",
       "            <th>method</th>\n",
       "            <th>page</th>\n",
       "            <th>registration</th>\n",
       "            <th>sessionid</th>\n",
       "            <th>song</th>\n",
       "            <th>status</th>\n",
       "            <th>ts</th>\n",
       "            <th>useragent</th>\n",
       "            <th>userid</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Amy Winehouse</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Ayla</td>\n",
       "            <td>F</td>\n",
       "            <td>0</td>\n",
       "            <td>Johnson</td>\n",
       "            <td>231.52280999999999</td>\n",
       "            <td>free</td>\n",
       "            <td>Santa Rosa, CA</td>\n",
       "            <td>PUT</td>\n",
       "            <td>NextSong</td>\n",
       "            <td>1540880381796</td>\n",
       "            <td>223</td>\n",
       "            <td>Stronger Than Me</td>\n",
       "            <td>200</td>\n",
       "            <td>1541550480796</td>\n",
       "            <td>&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.77.4 (KHTML, like Gecko) Version/7.0.5 Safari/537.77.4&quot;</td>\n",
       "            <td>63</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Cage The Elephant</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Kate</td>\n",
       "            <td>F</td>\n",
       "            <td>101</td>\n",
       "            <td>Harrell</td>\n",
       "            <td>175.12443999999999</td>\n",
       "            <td>paid</td>\n",
       "            <td>Lansing-East Lansing, MI</td>\n",
       "            <td>PUT</td>\n",
       "            <td>NextSong</td>\n",
       "            <td>1540472624796</td>\n",
       "            <td>293</td>\n",
       "            <td>Ain&#x27;t No Rest For The Wicked (Original Version)</td>\n",
       "            <td>200</td>\n",
       "            <td>1541551774796</td>\n",
       "            <td>&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36&quot;</td>\n",
       "            <td>97</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Yeah Yeah Yeahs</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Kaylee</td>\n",
       "            <td>F</td>\n",
       "            <td>3</td>\n",
       "            <td>Summers</td>\n",
       "            <td>220.96933999999999</td>\n",
       "            <td>free</td>\n",
       "            <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "            <td>PUT</td>\n",
       "            <td>NextSong</td>\n",
       "            <td>1540344794796</td>\n",
       "            <td>181</td>\n",
       "            <td>Heads Will Roll</td>\n",
       "            <td>200</td>\n",
       "            <td>1541554963796</td>\n",
       "            <td>&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36&quot;</td>\n",
       "            <td>8</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Juan Carlos Baglietto</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Wyatt</td>\n",
       "            <td>M</td>\n",
       "            <td>4</td>\n",
       "            <td>Scott</td>\n",
       "            <td>285.64852999999999</td>\n",
       "            <td>free</td>\n",
       "            <td>Eureka-Arcata-Fortuna, CA</td>\n",
       "            <td>PUT</td>\n",
       "            <td>NextSong</td>\n",
       "            <td>1540872073796</td>\n",
       "            <td>8</td>\n",
       "            <td>Era En Abril</td>\n",
       "            <td>200</td>\n",
       "            <td>1541560364796</td>\n",
       "            <td>Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko</td>\n",
       "            <td>9</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Jagged Edge featuring Run of Run DMC</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Adler</td>\n",
       "            <td>M</td>\n",
       "            <td>1</td>\n",
       "            <td>Barrera</td>\n",
       "            <td>248.37179</td>\n",
       "            <td>free</td>\n",
       "            <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "            <td>PUT</td>\n",
       "            <td>NextSong</td>\n",
       "            <td>1540835983796</td>\n",
       "            <td>301</td>\n",
       "            <td>Let&#x27;s Get Married</td>\n",
       "            <td>200</td>\n",
       "            <td>1541577508796</td>\n",
       "            <td>&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2&quot;</td>\n",
       "            <td>100</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Amy Winehouse', 'Logged In', 'Ayla', 'F', '0', 'Johnson', '231.52280999999999', 'free', 'Santa Rosa, CA', 'PUT', 'NextSong', '1540880381796', '223', 'Stronger Than Me', '200', '1541550480796', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.77.4 (KHTML, like Gecko) Version/7.0.5 Safari/537.77.4\"', '63'),\n",
       " ('Cage The Elephant', 'Logged In', 'Kate', 'F', '101', 'Harrell', '175.12443999999999', 'paid', 'Lansing-East Lansing, MI', 'PUT', 'NextSong', '1540472624796', '293', \"Ain't No Rest For The Wicked (Original Version)\", '200', '1541551774796', '\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"', '97'),\n",
       " ('Yeah Yeah Yeahs', 'Logged In', 'Kaylee', 'F', '3', 'Summers', '220.96933999999999', 'free', 'Phoenix-Mesa-Scottsdale, AZ', 'PUT', 'NextSong', '1540344794796', '181', 'Heads Will Roll', '200', '1541554963796', '\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"', '8'),\n",
       " ('Juan Carlos Baglietto', 'Logged In', 'Wyatt', 'M', '4', 'Scott', '285.64852999999999', 'free', 'Eureka-Arcata-Fortuna, CA', 'PUT', 'NextSong', '1540872073796', '8', 'Era En Abril', '200', '1541560364796', 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko', '9'),\n",
       " ('Jagged Edge featuring Run of Run DMC', 'Logged In', 'Adler', 'M', '1', 'Barrera', '248.37179', 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'PUT', 'NextSong', '1540835983796', '301', \"Let's Get Married\", '200', '1541577508796', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"', '100')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select *\n",
    "from staging_events \n",
    "where page = 'NextSong'\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Songs from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(1) from staging_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from stl_load_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "copy staging_songs \n",
    "from 's3://udacity-dend/song-data' \n",
    "iam_role 'arn:aws:iam::147551276302:role/dwhRole'\n",
    "region 'us-west-2'\n",
    "json 'auto ignorecase';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>604</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(604,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select COUNT(1)\n",
    "from staging_songs\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding how to convert ts into postgresql timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>ts</th>\n",
       "            <th>seconds_as_float</th>\n",
       "            <th>epoch_time_0</th>\n",
       "            <th>time_interval_from_epoch</th>\n",
       "            <th>start_time</th>\n",
       "            <th>artist</th>\n",
       "            <th>auth</th>\n",
       "            <th>firstname</th>\n",
       "            <th>gender</th>\n",
       "            <th>iteminsession</th>\n",
       "            <th>lastname</th>\n",
       "            <th>length</th>\n",
       "            <th>level</th>\n",
       "            <th>location</th>\n",
       "            <th>method</th>\n",
       "            <th>page</th>\n",
       "            <th>registration</th>\n",
       "            <th>sessionid</th>\n",
       "            <th>song</th>\n",
       "            <th>status</th>\n",
       "            <th>ts_1</th>\n",
       "            <th>useragent</th>\n",
       "            <th>userid</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1541300540796</td>\n",
       "            <td>1541300540.79600</td>\n",
       "            <td>1970-01-01 00:00:00</td>\n",
       "            <td>17839 days, 3:02:20.796000</td>\n",
       "            <td>2018-11-04 03:02:20.796000</td>\n",
       "            <td>Olivia Ruiz</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Jahiem</td>\n",
       "            <td>M</td>\n",
       "            <td>3</td>\n",
       "            <td>Miles</td>\n",
       "            <td>254.74566999999999</td>\n",
       "            <td>free</td>\n",
       "            <td>San Antonio-New Braunfels, TX</td>\n",
       "            <td>PUT</td>\n",
       "            <td>NextSong</td>\n",
       "            <td>1540817347796</td>\n",
       "            <td>42</td>\n",
       "            <td>Cabaret Blanco</td>\n",
       "            <td>200</td>\n",
       "            <td>1541300540796</td>\n",
       "            <td>&quot;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36&quot;</td>\n",
       "            <td>43</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1541310741796</td>\n",
       "            <td>1541310741.79600</td>\n",
       "            <td>1970-01-01 00:00:00</td>\n",
       "            <td>17839 days, 5:52:21.796000</td>\n",
       "            <td>2018-11-04 05:52:21.796000</td>\n",
       "            <td>None</td>\n",
       "            <td>Logged In</td>\n",
       "            <td>Jayden</td>\n",
       "            <td>M</td>\n",
       "            <td>5</td>\n",
       "            <td>Graves</td>\n",
       "            <td>None</td>\n",
       "            <td>paid</td>\n",
       "            <td>Marinette, WI-MI</td>\n",
       "            <td>GET</td>\n",
       "            <td>Home</td>\n",
       "            <td>1540664184796</td>\n",
       "            <td>128</td>\n",
       "            <td>None</td>\n",
       "            <td>200</td>\n",
       "            <td>1541310741796</td>\n",
       "            <td>&quot;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36&quot;</td>\n",
       "            <td>25</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('1541300540796', Decimal('1541300540.79600'), datetime.datetime(1970, 1, 1, 0, 0), datetime.timedelta(days=17839, seconds=10940, microseconds=796000), datetime.datetime(2018, 11, 4, 3, 2, 20, 796000), 'Olivia Ruiz', 'Logged In', 'Jahiem', 'M', '3', 'Miles', '254.74566999999999', 'free', 'San Antonio-New Braunfels, TX', 'PUT', 'NextSong', '1540817347796', '42', 'Cabaret Blanco', '200', '1541300540796', '\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', '43'),\n",
       " ('1541310741796', Decimal('1541310741.79600'), datetime.datetime(1970, 1, 1, 0, 0), datetime.timedelta(days=17839, seconds=21141, microseconds=796000), datetime.datetime(2018, 11, 4, 5, 52, 21, 796000), None, 'Logged In', 'Jayden', 'M', '5', 'Graves', None, 'paid', 'Marinette, WI-MI', 'GET', 'Home', '1540664184796', '128', None, '200', '1541310741796', '\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', '25')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select\n",
    "a.ts,\n",
    "(a.ts/1000) as seconds_as_float,\n",
    "TIMESTAMP 'epoch' as epoch_time_0,\n",
    "(a.ts/1000) * interval '1 second' as time_interval_from_epoch,\n",
    "TIMESTAMP 'epoch' + (a.ts/1000) * INTERVAL '1 Second ' AS start_time,\n",
    "a.*\n",
    "from staging_sparklify.staging_events a\n",
    "limit 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sql queries to transform the events and songs into dimension tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT xxxx,x,x,,,xx,\n",
    "           ROW_NUMBER() OVER(PARTITION BY userid ORDER BY ts DESC) AS rank\n",
    "    FROM staging_songs\n",
    "            WHERE zzz != NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>title</th>\n",
       "            <th>artist_id</th>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select \n",
    "    title,\n",
    "    artist_id,\n",
    "    count(1)\n",
    "from staging_songs\n",
    "group by title,\n",
    "    artist_id\n",
    "having count(1)> 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>song_id</th>\n",
       "            <th>title</th>\n",
       "            <th>artist_id</th>\n",
       "            <th>year</th>\n",
       "            <th>duration</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>SODZYPO12A8C13A91E</td>\n",
       "            <td>Burn My Body (Album Version)</td>\n",
       "            <td>AR1C2IX1187B99BF74</td>\n",
       "            <td>0</td>\n",
       "            <td>177.99790999999999</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOTAZDY12AB0187616</td>\n",
       "            <td>Drillbit</td>\n",
       "            <td>ARZKCQM1257509D107</td>\n",
       "            <td>0</td>\n",
       "            <td>374.62159000000003</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOIGHOD12A8C13B5A1</td>\n",
       "            <td>Indian Angel</td>\n",
       "            <td>ARY589G1187B9A9F4E</td>\n",
       "            <td>2004</td>\n",
       "            <td>171.57178999999999</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOFRDWL12A58A7CEF7</td>\n",
       "            <td>Hit Da Scene</td>\n",
       "            <td>AR9Q9YC1187FB5609B</td>\n",
       "            <td>0</td>\n",
       "            <td>252.94322</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SORRNOC12AB017F52B</td>\n",
       "            <td>The Last Beat Of My Heart (b-side)</td>\n",
       "            <td>ARSZ7L31187FB4E610</td>\n",
       "            <td>2004</td>\n",
       "            <td>337.81506000000002</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SONQPZK12AB0182D84</td>\n",
       "            <td>Double Wide</td>\n",
       "            <td>ARKYKXP11F50C47A6A</td>\n",
       "            <td>0</td>\n",
       "            <td>160.20853</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOIGICF12A8C141BC5</td>\n",
       "            <td>Game &amp; Watch</td>\n",
       "            <td>AREWD471187FB49873</td>\n",
       "            <td>2004</td>\n",
       "            <td>580.54485</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOBRKGM12A8C139EF6</td>\n",
       "            <td>Welcome to the Pleasuredome</td>\n",
       "            <td>ARXQBR11187B98A2CC</td>\n",
       "            <td>1985</td>\n",
       "            <td>821.05424000000005</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOHOZBI12A8C132E3C</td>\n",
       "            <td>Smash It Up</td>\n",
       "            <td>AR0MWD61187B9B2B12</td>\n",
       "            <td>2000</td>\n",
       "            <td>195.39546000000001</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SOCIWDW12A8C13D406</td>\n",
       "            <td>Soul Deep</td>\n",
       "            <td>ARMJAGH1187FB546F3</td>\n",
       "            <td>1969</td>\n",
       "            <td>148.03546</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('SODZYPO12A8C13A91E', 'Burn My Body (Album Version)', 'AR1C2IX1187B99BF74', 0, '177.99790999999999'),\n",
       " ('SOTAZDY12AB0187616', 'Drillbit', 'ARZKCQM1257509D107', 0, '374.62159000000003'),\n",
       " ('SOIGHOD12A8C13B5A1', 'Indian Angel', 'ARY589G1187B9A9F4E', 2004, '171.57178999999999'),\n",
       " ('SOFRDWL12A58A7CEF7', 'Hit Da Scene', 'AR9Q9YC1187FB5609B', 0, '252.94322'),\n",
       " ('SORRNOC12AB017F52B', 'The Last Beat Of My Heart (b-side)', 'ARSZ7L31187FB4E610', 2004, '337.81506000000002'),\n",
       " ('SONQPZK12AB0182D84', 'Double Wide', 'ARKYKXP11F50C47A6A', 0, '160.20853'),\n",
       " ('SOIGICF12A8C141BC5', 'Game & Watch', 'AREWD471187FB49873', 2004, '580.54485'),\n",
       " ('SOBRKGM12A8C139EF6', 'Welcome to the Pleasuredome', 'ARXQBR11187B98A2CC', 1985, '821.05424000000005'),\n",
       " ('SOHOZBI12A8C132E3C', 'Smash It Up', 'AR0MWD61187B9B2B12', 2000, '195.39546000000001'),\n",
       " ('SOCIWDW12A8C13D406', 'Soul Deep', 'ARMJAGH1187FB546F3', 1969, '148.03546')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select \n",
    "song_id,\n",
    "title,\n",
    "artist_id,\n",
    "year::int,\n",
    "duration\n",
    "from staging_songs\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cuvu38ujek21.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into songs\n",
    "(song_id,title,artist_id,year,duration)\n",
    "select \n",
    "song_id,\n",
    "title,\n",
    "artist_id,\n",
    "year::int,\n",
    "duration\n",
    "from staging_sparklify.staging_songs\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addressed in artist_cleaning Notebook\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/11904085/168094814-9ec453db-19ea-4e4b-b888-a51aa7402167.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load songplays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.InvalidSchemaName) schema \"staging_sparklify\" does not exist\n",
      "\n",
      "[SQL: select \n",
      "'songplay_id' as songplay_id,\n",
      "TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,\n",
      "e.userid as user_id,\n",
      "e.level,\n",
      "s.song_id,\n",
      "e.song as song_title,\n",
      "s.artist_id,\n",
      "e.artist as artist_name,\n",
      "e.sessionid as session_id,\n",
      "e.location,\n",
      "e.userAgent as user_agent,\n",
      "e.length as stream_dureation\n",
      "from staging_sparklify.staging_events e\n",
      "left join staging_sparklify.staging_songs s on e.song = s.title and e.artist = s.artist_name\n",
      "where page = 'NextSong'\n",
      "and s.artist_id is null\n",
      "limit 5]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select \n",
    "'songplay_id' as songplay_id,\n",
    "TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,\n",
    "e.userid as user_id,\n",
    "e.level,\n",
    "s.song_id,\n",
    "e.song as song_title,\n",
    "s.artist_id,\n",
    "e.artist as artist_name,\n",
    "e.sessionid as session_id,\n",
    "e.location,\n",
    "e.userAgent as user_agent,\n",
    "e.length as stream_dureation\n",
    "from staging_sparklify.staging_events e\n",
    "left join staging_sparklify.staging_songs s on e.song = s.title and e.artist = s.artist_name\n",
    "where page = 'NextSong'\n",
    "and s.artist_id is null\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.UndefinedTable) relation \"songplays\" does not exist\n",
      "\n",
      "[SQL: insert into songplays\n",
      "(start_time, user_id, level, song_id, song_title, \n",
      "artist_id, artist_name, session_id, location, user_agent, stream_duration)\n",
      "select \n",
      "TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,\n",
      "e.userid::int as user_id,\n",
      "e.level,\n",
      "s.song_id,\n",
      "e.song as song_title,\n",
      "s.artist_id,\n",
      "e.artist as artist_name,\n",
      "e.sessionid::int as session_id,\n",
      "e.location,\n",
      "e.userAgent as user_agent,\n",
      "e.length::decimal as stream_dureation\n",
      "from staging_sparklify.staging_events e\n",
      "left join staging_sparklify.staging_songs s on e.song = s.title and e.artist = s.artist_name\n",
      "where page = 'NextSong'\n",
      "and s.artist_id is null\n",
      "limit 5]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into songplays\n",
    "(start_time, user_id, level, song_id, song_title, \n",
    "artist_id, artist_name, session_id, location, user_agent, stream_duration)\n",
    "select \n",
    "TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,\n",
    "e.userid::int as user_id,\n",
    "e.level,\n",
    "s.song_id,\n",
    "e.song as song_title,\n",
    "s.artist_id,\n",
    "e.artist as artist_name,\n",
    "e.sessionid::int as session_id,\n",
    "e.location,\n",
    "e.userAgent as user_agent,\n",
    "e.length::decimal as stream_dureation\n",
    "from staging_sparklify.staging_events e\n",
    "left join staging_sparklify.staging_songs s on e.song = s.title and e.artist = s.artist_name\n",
    "where page = 'NextSong'\n",
    "and s.artist_id is null\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Time Dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "14 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>time_key</th>\n",
       "            <th>timestamp_date</th>\n",
       "            <th>year</th>\n",
       "            <th>month</th>\n",
       "            <th>day</th>\n",
       "            <th>hour</th>\n",
       "            <th>week</th>\n",
       "            <th>day_of_week</th>\n",
       "            <th>day_of_week_name</th>\n",
       "            <th>is_weekend</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2018110607</td>\n",
       "            <td>2018-11-06 07:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>6</td>\n",
       "            <td>7</td>\n",
       "            <td>45</td>\n",
       "            <td>2</td>\n",
       "            <td>Tuesday  </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110706</td>\n",
       "            <td>2018-11-07 06:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>7</td>\n",
       "            <td>6</td>\n",
       "            <td>45</td>\n",
       "            <td>3</td>\n",
       "            <td>Wednesday</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110410</td>\n",
       "            <td>2018-11-04 10:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>4</td>\n",
       "            <td>10</td>\n",
       "            <td>44</td>\n",
       "            <td>0</td>\n",
       "            <td>Sunday   </td>\n",
       "            <td>True</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110416</td>\n",
       "            <td>2018-11-04 16:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>4</td>\n",
       "            <td>16</td>\n",
       "            <td>44</td>\n",
       "            <td>0</td>\n",
       "            <td>Sunday   </td>\n",
       "            <td>True</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110916</td>\n",
       "            <td>2018-11-09 16:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>9</td>\n",
       "            <td>16</td>\n",
       "            <td>45</td>\n",
       "            <td>5</td>\n",
       "            <td>Friday   </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110808</td>\n",
       "            <td>2018-11-08 08:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>8</td>\n",
       "            <td>8</td>\n",
       "            <td>45</td>\n",
       "            <td>4</td>\n",
       "            <td>Thursday </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110809</td>\n",
       "            <td>2018-11-08 09:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>8</td>\n",
       "            <td>9</td>\n",
       "            <td>45</td>\n",
       "            <td>4</td>\n",
       "            <td>Thursday </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018111513</td>\n",
       "            <td>2018-11-15 13:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>15</td>\n",
       "            <td>13</td>\n",
       "            <td>46</td>\n",
       "            <td>4</td>\n",
       "            <td>Thursday </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110203</td>\n",
       "            <td>2018-11-02 03:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>2</td>\n",
       "            <td>3</td>\n",
       "            <td>44</td>\n",
       "            <td>5</td>\n",
       "            <td>Friday   </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110212</td>\n",
       "            <td>2018-11-02 12:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>2</td>\n",
       "            <td>12</td>\n",
       "            <td>44</td>\n",
       "            <td>5</td>\n",
       "            <td>Friday   </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018111404</td>\n",
       "            <td>2018-11-14 04:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>14</td>\n",
       "            <td>4</td>\n",
       "            <td>46</td>\n",
       "            <td>3</td>\n",
       "            <td>Wednesday</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018111410</td>\n",
       "            <td>2018-11-14 10:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>14</td>\n",
       "            <td>10</td>\n",
       "            <td>46</td>\n",
       "            <td>3</td>\n",
       "            <td>Wednesday</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018110518</td>\n",
       "            <td>2018-11-05 18:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>5</td>\n",
       "            <td>18</td>\n",
       "            <td>45</td>\n",
       "            <td>1</td>\n",
       "            <td>Monday   </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2018111305</td>\n",
       "            <td>2018-11-13 05:00:00+00:00</td>\n",
       "            <td>2018</td>\n",
       "            <td>11</td>\n",
       "            <td>13</td>\n",
       "            <td>5</td>\n",
       "            <td>46</td>\n",
       "            <td>2</td>\n",
       "            <td>Tuesday  </td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2018110607, datetime.datetime(2018, 11, 6, 7, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 6, 7, 45, 2, 'Tuesday  ', False),\n",
       " (2018110706, datetime.datetime(2018, 11, 7, 6, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 7, 6, 45, 3, 'Wednesday', False),\n",
       " (2018110410, datetime.datetime(2018, 11, 4, 10, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 4, 10, 44, 0, 'Sunday   ', True),\n",
       " (2018110416, datetime.datetime(2018, 11, 4, 16, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 4, 16, 44, 0, 'Sunday   ', True),\n",
       " (2018110916, datetime.datetime(2018, 11, 9, 16, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 9, 16, 45, 5, 'Friday   ', False),\n",
       " (2018110808, datetime.datetime(2018, 11, 8, 8, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 8, 8, 45, 4, 'Thursday ', False),\n",
       " (2018110809, datetime.datetime(2018, 11, 8, 9, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 8, 9, 45, 4, 'Thursday ', False),\n",
       " (2018111513, datetime.datetime(2018, 11, 15, 13, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 15, 13, 46, 4, 'Thursday ', False),\n",
       " (2018110203, datetime.datetime(2018, 11, 2, 3, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 2, 3, 44, 5, 'Friday   ', False),\n",
       " (2018110212, datetime.datetime(2018, 11, 2, 12, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 2, 12, 44, 5, 'Friday   ', False),\n",
       " (2018111404, datetime.datetime(2018, 11, 14, 4, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 14, 4, 46, 3, 'Wednesday', False),\n",
       " (2018111410, datetime.datetime(2018, 11, 14, 10, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 14, 10, 46, 3, 'Wednesday', False),\n",
       " (2018110518, datetime.datetime(2018, 11, 5, 18, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 5, 18, 45, 1, 'Monday   ', False),\n",
       " (2018111305, datetime.datetime(2018, 11, 13, 5, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 2018, 11, 13, 5, 46, 2, 'Tuesday  ', False)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "with time_relevant_records as (\n",
    "    select TIMESTAMP 'epoch' + (ts/1000) * INTERVAL '1 Second ' as start_time,    \n",
    "    extract(hour from start_time) as hour,\n",
    "    extract(day from start_time) as day,\n",
    "    extract(week from start_time) as week,\n",
    "    extract(month from start_time) as month,\n",
    "    extract(year from start_time) as year,\n",
    "    TO_TIMESTAMP(year || '-' || month || '-' || day || ' ' || hour || ':00:00', 'YYYY-MM-DD HH24:MI:SS') as timestamp_date\n",
    "    from staging_events \n",
    "    where page = 'NextSong'\n",
    ")\n",
    "select distinct\n",
    "    year * 1000000\n",
    "    + month * 10000\n",
    "    + day * 100\n",
    "    + hour \n",
    "    as time_key,\n",
    "    timestamp_date,\n",
    "    extract(year from start_time) as year,\n",
    "    extract(month from start_time) as month,\n",
    "    extract(day from start_time) as day,\n",
    "    extract(hour from start_time) as hour,    \n",
    "    extract(week from start_time) as week,    \n",
    "    extract(dayofweek from start_time) as day_of_week,\n",
    "    to_char(start_time, 'Day') as day_of_week_name,\n",
    "    day_of_week in (0,6) as is_weekend\n",
    "from time_relevant_records\n",
    "limit 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.SyntaxError) syntax error at or near \"select\"\n",
      "LINE 3: select distinct\n",
      "        ^\n",
      "\n",
      "[SQL: with time_relevant_records as \n",
      "\n",
      "select distinct\n",
      "extract(hour from start_time) as hour,\n",
      "extract(day from start_time) as day,\n",
      "extract(week from start_time) as week,\n",
      "extract(month from start_time) as month,\n",
      "extract(year from start_time) as year,\n",
      "+ year * 1000000\n",
      "+ month * 10000\n",
      "+ day * 100\n",
      "+ hour \n",
      "as time_key,\n",
      "extract(dayofweek from start_time) as day_of_week,\n",
      "to_char(start_time, 'Day') as day_of_week_name,\n",
      "day_of_week in (0,6) as is_weekend\n",
      "from staging_events e\n",
      "where page = 'NextSong'\n",
      "order by song\n",
      "limit 10]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "with time_relevant_records as \n",
    "\n",
    "select distinct\n",
    "extract(hour from start_time) as hour,\n",
    "extract(day from start_time) as day,\n",
    "extract(week from start_time) as week,\n",
    "extract(month from start_time) as month,\n",
    "extract(year from start_time) as year,\n",
    "+ year * 1000000\n",
    "+ month * 10000\n",
    "+ day * 100\n",
    "+ hour \n",
    "as time_key,\n",
    "extract(dayofweek from start_time) as day_of_week,\n",
    "to_char(start_time, 'Day') as day_of_week_name,\n",
    "day_of_week in (0,6) as is_weekend\n",
    "from staging_events e\n",
    "where page = 'NextSong'\n",
    "order by song\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.UndefinedTable) relation \"time\" does not exist\n",
      "\n",
      "[SQL: insert into time \n",
      "(start_time, hour, day, week, month, year, day_of_week, day_of_week_name, is_weekend)\n",
      "select distinct\n",
      "    TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,\n",
      "    extract(hour from start_time) as hour,\n",
      "    extract(day from start_time) as day,\n",
      "    extract(week from start_time) as week,\n",
      "    extract(month from start_time) as month,\n",
      "    extract(year from start_time) as year,\n",
      "    extract(dayofweek from start_time) as day_of_week,\n",
      "    to_char(start_time, 'Day') as day_of_week_name,\n",
      "    day_of_week in (0,6) as is_weekend\n",
      "from staging_events e\n",
      "where page = 'NextSong'\n",
      "order by start_time]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "insert into time \n",
    "(start_time, hour, day, week, month, year, day_of_week, day_of_week_name, is_weekend)\n",
    "select distinct\n",
    "    TIMESTAMP 'epoch' + (e.ts/1000) * INTERVAL '1 Second ' as start_time,\n",
    "    extract(hour from start_time) as hour,\n",
    "    extract(day from start_time) as day,\n",
    "    extract(week from start_time) as week,\n",
    "    extract(month from start_time) as month,\n",
    "    extract(year from start_time) as year,\n",
    "    extract(dayofweek from start_time) as day_of_week,\n",
    "    to_char(start_time, 'Day') as day_of_week_name,\n",
    "    day_of_week in (0,6) as is_weekend\n",
    "from staging_events e\n",
    "where page = 'NextSong'\n",
    "order by start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.UndefinedTable) relation \"time\" does not exist\n",
      "\n",
      "[SQL: select * \n",
      "from time\n",
      "limit 14]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select * \n",
    "from time\n",
    "limit 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load User Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.InvalidSchemaName) schema \"staging_sparklify\" does not exist\n",
      "\n",
      "[SQL: select distinct\n",
      "userid as user_id,\n",
      "firstname as first_name,\n",
      "lastname as last_name,\n",
      "gender,\n",
      "level\n",
      "from staging_sparklify.staging_events e\n",
      "where page = 'NextSong'\n",
      "order by song\n",
      "limit 10]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql \n",
    "select distinct\n",
    "userid as user_id,\n",
    "firstname as first_name,\n",
    "lastname as last_name,\n",
    "gender,\n",
    "level\n",
    "from staging_sparklify.staging_events e\n",
    "where page = 'NextSong'\n",
    "order by song\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.UndefinedTable) relation \"users\" does not exist\n",
      "\n",
      "[SQL: insert into users\n",
      "(user_id, first_name, last_name, gender, level)\n",
      "select distinct\n",
      "userid::int as user_id,\n",
      "firstname as first_name,\n",
      "lastname as last_name,\n",
      "gender,\n",
      "level\n",
      "from staging_sparklify.staging_events e\n",
      "where page = 'NextSong'\n",
      "order by song\n",
      "limit 10]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "insert into users\n",
    "(user_id, first_name, last_name, gender, level)\n",
    "select distinct\n",
    "userid::int as user_id,\n",
    "firstname as first_name,\n",
    "lastname as last_name,\n",
    "gender,\n",
    "level\n",
    "from staging_sparklify.staging_events e\n",
    "where page = 'NextSong'\n",
    "order by song\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues\n",
    "It looks like the files being read from 's3://udacity-dend/log-data' have a different encoding and I have records that do not match artst / song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.InvalidSchemaName) schema \"staging_sparklify\" does not exist\n",
      "\n",
      "[SQL: select *\n",
      "from staging_sparklify.staging_songs\n",
      "where title in ('Get Me Bodied',  'Los Salieris De Charly')\n",
      "or artist_name = 'Mpiri'\n",
      "limit 20]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select *\n",
    "from staging_sparklify.staging_songs\n",
    "where title in ('Get Me Bodied',  'Los Salieris De Charly')\n",
    "or artist_name = 'Mpiri'\n",
    "limit 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cmfoxim90hks.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.errors.UndefinedTable) relation \"songs\" does not exist\n",
      "\n",
      "[SQL: select * from songs\n",
      "limit 10;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql \n",
    "select * from songs\n",
    "limit 10;"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34383ae59924545d0fc2d9bbd305fb33513ef5b060808b9407ab14ab66bb7ddc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
